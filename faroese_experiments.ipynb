{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "from tokenizers import trainers\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "#from torchsummary import summary\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from conllu import parse_incr\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, path, txt_file, tokenizer, max_length):\n",
    "        super(BERTDataset, self).__init__()\n",
    "        self.path = path\n",
    "        self.train_set = pd.read_csv(txt_file, delimiter='\\t', header=None, index_col=None)\n",
    "        self.train_set.drop(0, inplace=True, axis=1)\n",
    "        self.max_length = max_length\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_set)\n",
    "    def __getitem__(self, index):\n",
    "        sent_1 = self.train_set.iloc[index]\n",
    "        # print(sent_1) for debugging\n",
    "        inputs = self.tokenizer.encode_plus(sent_1, truncation=True, max_length=self.max_length, return_attention_mask=True, return_tensors=\"pt\")\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "        return {\"ids\": torch.tensor(ids, dtype=torch.long), \"mask\": torch.tensor(mask, dtype=torch.long), \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_file = open(\"UD_Faroese-OFT/fo_oft-ud-test.conllu\", \"r\", encoding=\"utf-8\")  # https://www.youtube.com/watch?v=lvJRFMvWtFI\n",
    "faroese_oft = [sent for sent in parse_incr(eval_file)]\n",
    "\n",
    "def read_conll(input_file):\n",
    "    regexSent = re.compile(r\"^#\\stext\\s=\\s\")\n",
    "    text_oft = list()\n",
    "    for line in open(input_file, encoding=\"utf-8\"):\n",
    "        if line.startswith(\"# text =\"):\n",
    "            text_oft.append(regexSent.sub('', line))\n",
    "    return text_oft\n",
    "\n",
    "texts = \"\\n\".join(read_conll(\"UD_Faroese-OFT/fo_oft-ud-test.conllu\"))\n",
    "texts = tokenizer.tokenize(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file = \"fao_wikipedia_2021_30K-sentences.txt\"\n",
    "\n",
    "f = open(corpus_file, 'r', encoding=\"utf-8\")\n",
    "faroese_Regex = re.compile(r\"^\\d+\\s+\")\n",
    "faroese_sents = [faroese_Regex.sub('', sent) for sent in f.readlines()]  # for faroese\n",
    "faroese_words = [sent.split() for sent in faroese_sents]\n",
    "punc_tokens = ['“', '”', '´', '`', '–', '‐', '’', '‘', '—', '…']\n",
    "faroese_words = [word for sent in faroese_words for word in sent]\n",
    "f.close()\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "dataset = BERTDataset('.', corpus_file, tokenizer, max_length=100)\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fineBERT(torch.nn.Module): \n",
    "    def __init__(self):\n",
    "        super(fineBERT, self).__init__()\n",
    "        self.bert_model = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "        self.out = torch.nn.Linear(768, 1)  # update layer size\n",
    "\n",
    "    def forward(self, ids, mask, token_type_ids):\n",
    "        _, output = self.bert_model(ids, attention_mask=mask, token_type_ids=token_type_ids, return_dict=False)\n",
    "        return self.out(output)\n",
    "    \n",
    "\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "model = fineBERT()\n",
    "optimizer= optim.Adam(model.parameters(),lr= 0.0001)\n",
    "\n",
    "for param in model.bert_model.parameters():\n",
    "        param.requires_grad = False"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
