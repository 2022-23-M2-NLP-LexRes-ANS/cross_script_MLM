{"cells":[{"cell_type":"code","source":["!pip install torch transformers conllu unidecode pandas numpy datasets evaluate colorama lime"],"metadata":{"id":"PieF2ksZpQP-"},"id":"PieF2ksZpQP-","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"22a9da31","metadata":{"tags":[],"id":"22a9da31","outputId":"d4db5069-61d5-44e3-e612-d1c7eb63ab68"},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/andres-gon/Documents/LCT-Tasks/UoL/courses/analyse_lexicologique/lexical_resources/lexical-snake/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import lime\n","import torch\n","import torch.nn.functional as F\n","from lime.lime_text import LimeTextExplainer\n","from torch import cuda\n","from transformers import AutoTokenizer, AutoModelForTokenClassification\n","import re\n","import os"]},{"cell_type":"code","execution_count":null,"id":"d4b4cf1b","metadata":{"id":"d4b4cf1b"},"outputs":[],"source":["\n","class NERExplainerGenerator:\n","    \n","    def __init__(self, model_dir, number_of_labels, device):\n","        self.model = AutoModelForTokenClassification.from_pretrained(model_dir, num_labels=number_of_labels)\n","        self.model = self.model.to(device)\n","        self.tokenizer = AutoTokenizer.from_pretrained(model_dir, use_fast=True)\n","        \n","    def clean(self, sent):\n","        \n","        sentence = sent.strip().split() \n","        pattern = re.compile(\"\\ufffd|\\u200e|\\u200b\\u200b|\\u200b|\\u200c|\\u200f|\\xad|\\u0654|\\u0652|\\u0651|\\u0650|\\u0657|\\u0656|\\u064e|\\u064b|\\u0670|\\u064f|\\u064f\",re.UNICODE)\n","        sentence = [pattern.sub('-',e) for e in sentence]\n","        sentence = [e.replace('-','') if len(e)>1 else e for e in sentence]\n","        \n","        return sentence\n","    \n","    def tokenize(self, sent):\n","        \n","        tokenized = self.tokenizer(sent,\n","         is_split_into_words=True, \n","         return_offsets_mapping=True, \n","         padding='max_length', \n","         truncation=True, \n","         max_length=256)\n","        \n","        \n","        return tokenized\n","    \n","\n","    def get_predict_function(self, word_index, batch_size = 8):\n","        def predict_func(texts):\n","            \n","            tokenized = [self.tokenize(self.clean(text)) for text in texts]\n","            \n","            probas = None\n","            for i in range(0,len(tokenized),batch_size):\n","                \n","                if i+batch_size > len(tokenized):\n","                    j = len(tokenized)\n","                else:\n","                    j = i+batch_size\n","                    \n","                batch = tokenized[i:j]\n","                \n","                inp_ids = torch.as_tensor([b['input_ids'] for b in batch]).to(device)\n","                mask = torch.as_tensor([b['attention_mask'] for b in batch]).to(device)\n","                logits = self.model(input_ids=inp_ids, attention_mask=mask).logits\n","                probas_batch = F.softmax(logits, dim=-1).detach().numpy()\n","                \n","                if probas is None:\n","                    probas = probas_batch\n","                else:\n","                    probas = np.vstack((probas,probas_batch))\n","      \n","\n","            print(probas.shape)\n","            return probas[:,word_index,:]\n","        \n","        return predict_func"]},{"cell_type":"code","execution_count":null,"id":"a54e6b40","metadata":{"id":"a54e6b40"},"outputs":[],"source":["tags = ['NOUN','VERB','ADP', 'PUNCT', 'DET', 'SCONJ','ADJ', 'PRON', 'ADV', 'AUX','PROPN','CCONJ','NUM','X', 'SYM', 'PART', 'INTJ']\n","\n","\n","# device = 'cuda' if cuda.is_available() else 'cpu'\n","device = 'cpu'\n"]},{"cell_type":"code","execution_count":null,"id":"be234704","metadata":{"id":"be234704"},"outputs":[],"source":["def get_token_idx(sent, labels, tags):\n","    tokenized = model.tokenize(sent.split())\n","    offset = tokenized['offset_mapping']\n","    index = [i for i,(a,b) in enumerate(offset) if a==0 and b!=0 and tokenized['input_ids'][i]!=6]\n","    tag_to_id = {t:i for i,t in enumerate(tags)}\n","    labels = labels.split()\n","    wordIds_to_tokenidx = [(ti,tag_to_id[labels[wi]]) for wi,ti in enumerate(index)]\n","    \n","    return wordIds_to_tokenidx\n","    "]},{"cell_type":"code","execution_count":null,"id":"2a30b478","metadata":{"id":"2a30b478"},"outputs":[],"source":["def explain(model, explainer, tags, data, idx):\n","    \n","    original_sent = data.iloc[idx].sent\n","    augmented_sent = data.iloc[idx].augmented_sen\n","    labels = data.iloc[idx].predictions\n","    \n","    ids = get_token_idx(original_sent, labels, tags)\n","    \n","    for i, (word_index, label_index) in enumerate(ids):\n","        \n","        func = model.get_predict_function(word_index)\n","        \n","        exp = explainer.explain_instance(augmented_sent, func, \n","                                         num_features=20, num_samples=20, labels=(label_index,))\n","        \n","        dir_ = './visualizations'\n","        if not os.path.exists(dir_):\n","            os.mkdir(dir_)\n","        if not os.path.exists(f'{dir_}/{str(idx)}'):\n","            os.mkdir(f'{dir_}/{str(idx)}')   \n","        \n","        \n","        filename = f'{dir_}/{str(idx)}/{original_sent.split()[i]}.html'\n","        exp.save_to_file(filename, text=augmented_sent)"]},{"cell_type":"code","execution_count":null,"id":"048b95ee","metadata":{"id":"048b95ee"},"outputs":[],"source":["LANG = 'en' # use None for all lang\n","MAX_LEN = 256\n","\n","#MODEL_NAME = 'xlm-roberta-large'\n","\n","MODEL_NAME = 'distilbert-base-uncased'\n","#SET = 'LM' # 'LM' or None\n","EVAL_SET = 'test'\n","#augmented_data_dir = '../Data-Processing/Augmented-Dataset'\n","#conll_data_dir = '../Dataset'"]},{"cell_type":"code","execution_count":null,"id":"8d5cbe68-b5eb-45ed-94b2-85a460b01505","metadata":{"id":"8d5cbe68-b5eb-45ed-94b2-85a460b01505"},"outputs":[],"source":["filename = f'{augmented_data_dir}/{LANG}-{EVAL_SET}-{SET}.csv'\n","data = pd.read_csv(filename)\n","output = pd.read_csv(f'./{LANG}/{EVAL_SET}/outputs-{MODEL_NAME}-{SET}.csv')\n","data['predictions'] = output['predictions'].array\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"53ba047f","metadata":{"id":"53ba047f"},"outputs":[],"source":["# if SET=='LM' or SET=='tags':\n","#     filename = f'{augmented_data_dir}/{LANG}-{EVAL_SET}-{SET}.csv'\n","#     data = pd.read_csv(filename)\n","#     output = pd.read_csv(f'./{LANG}/{EVAL_SET}/outputs-{MODEL_NAME}-{SET}.csv')\n","#     data['predictions'] = output['predictions'].array\n","    \n","# else:\n","#     filename = f'{conll_data_dir}/{LANG}/{LANG}_{EVAL_SET}.conll'\n","#     data = prepare_data(filename)\n","#     output = pd.read_csv(f'./{LANG}/{EVAL_SET}/outputs-{MODEL_NAME}.csv')\n","#     data['predictions'] = output['predictions'].array"]},{"cell_type":"code","execution_count":null,"id":"b22bb560","metadata":{"id":"b22bb560"},"outputs":[],"source":["model = NERExplainerGenerator(f'../Experiment/output/{MODEL_NAME}-{LANG}-{SET}', len(tags), device)\n","explainer = LimeTextExplainer(class_names=tags, random_state=42)"]},{"cell_type":"code","execution_count":null,"id":"3210de30","metadata":{"id":"3210de30","outputId":"9b2a2f13-b8d2-4de1-87e4-fe60023e6d41"},"outputs":[{"name":"stdout","output_type":"stream","text":["(20, 256, 14)\n","(20, 256, 14)\n","(20, 256, 14)\n"]}],"source":["explain(model, explainer, tags, data, 10)"]},{"cell_type":"code","execution_count":null,"id":"db639ddf","metadata":{"id":"db639ddf","outputId":"691a249b-5631-488b-f150-ae36b92a57ed"},"outputs":[{"data":{"text/plain":["ID               87c2c8f4-1c9c-425d-803f-c91686630c5c\n","lang                                         en-orcas\n","sent                               mayor  of  arugba \n","labels                                     O  O  B-CW\n","augmented_sen                      mayor  of  arugba \n","predictions                                 O O B-LOC\n","Name: 173299, dtype: object"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["data.iloc[173299]"]},{"cell_type":"code","execution_count":null,"id":"747809c3","metadata":{"id":"747809c3"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}